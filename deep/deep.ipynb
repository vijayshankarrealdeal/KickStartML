{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\r\n",
    "    A = 1 / (1+np.exp(-Z))\r\n",
    "    cache = Z\r\n",
    "    return A,cache\r\n",
    "\r\n",
    "\r\n",
    "def relu(Z):\r\n",
    "    A = np.maximum(0,Z)\r\n",
    "    cache = Z\r\n",
    "    return A,cache\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_back(dA,cache):\r\n",
    "    Z = cache\r\n",
    "    s = 1 + (1+ np.exp(-Z))\r\n",
    "    dZ = dA * s*(1-s)\r\n",
    "    return dZ\r\n",
    "\r\n",
    "def relu_back(dA,cache):\r\n",
    "    Z = cache\r\n",
    "    dZ = np.array(dA,copy = True)\r\n",
    "    dZ[Z<=0] = 0\r\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layers_dims):\r\n",
    "    parameters = {}\r\n",
    "    L = len(layers_dims)\r\n",
    "    for i in range(1,L):\r\n",
    "        parameters[\"W\"+str(i)] = np.random.randn(layers_dims[i],layers_dims[i-1])\r\n",
    "        parameters[\"b\"+str(i)] = np.zeros((layers_dims[i],1))\r\n",
    "\r\n",
    "        \r\n",
    "        assert(parameters['W' + str(i)].shape == (layers_dims[i], layers_dims[i-1]))\r\n",
    "        assert(parameters['b' + str(i)].shape == (layers_dims[i], 1))\r\n",
    "    return parameters\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A,W,b):\r\n",
    "    Z = np.dot(W,A) + b\r\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\r\n",
    "    cache = (A,W,b)\r\n",
    "    return Z,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forword(A_prev,W,b,activation):\r\n",
    "    if activation == \"sigmoid\":\r\n",
    "        Z,linear_cache = linear_forward(A_prev,W,b)\r\n",
    "        A,activation_cache = sigmoid(Z)\r\n",
    "    elif activation == \"relu\":\r\n",
    "        Z,linear_cache = linear_forward(A_prev,W,b)\r\n",
    "        A,activation_cache = relu(Z)\r\n",
    "    cache = (linear_cache,activation_cache)\r\n",
    "    return A,cache\r\n",
    "\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X,parameters):\r\n",
    "    A = X\r\n",
    "    L =  len(parameters)//2\r\n",
    "    caches = []\r\n",
    "    for i in range(1,L):\r\n",
    "        A_prev  = A\r\n",
    "        A,cache = linear_activation_forword(A_prev,parameters[\"W\"+str(i)],parameters[\"b\"+str(i)],\"relu\")\r\n",
    "        caches.append(cache)\r\n",
    "\r\n",
    "    AL,cache = linear_activation_forword(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],\"sigmoid\")\r\n",
    "    caches.append(cache)\r\n",
    "\r\n",
    "    return AL,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL,Y):\r\n",
    "    m = Y.shape[1]\r\n",
    "    \r\n",
    "    #logprodut =  np.square(AL-Y) \r\n",
    "    logprodut = np.dot(Y,np.log(AL).T) + np.dot((1-Y),np.log(1-AL).T)\r\n",
    "    cost = 1/m * logprodut\r\n",
    "    cost = np.squeeze(cost) \r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ,cache):\r\n",
    "    A_prev,W,b = cache\r\n",
    "    m = A_prev.shape[1]\r\n",
    "\r\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\r\n",
    "    db = 1./m * np.sum(dZ,axis= 1 ,keepdims= True)\r\n",
    "    dA_prev = np.dot(W.T,dZ)\r\n",
    "\r\n",
    "    assert (dA_prev.shape == A_prev.shape)\r\n",
    "    assert (dW.shape == W.shape)\r\n",
    "    assert (db.shape == b.shape)\r\n",
    "\r\n",
    "    return dA_prev,dW,db\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA,cache,activation):\r\n",
    "    linear_cache,activation_cache = cache\r\n",
    "\r\n",
    "    if activation == \"relu\":\r\n",
    "        dZ = relu_back(dA,activation_cache)\r\n",
    "        dA_prev,dW,db = linear_backward(dZ,linear_cache)\r\n",
    "\r\n",
    "    elif activation == \"sigmoid\":\r\n",
    "        dZ = sigmoid_back(dA,activation_cache)\r\n",
    "        dA_prev,dW,db = linear_backward(dZ,linear_cache)\r\n",
    "    \r\n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(AL,Y,caches):\r\n",
    "    grads = {}\r\n",
    "    L = len(caches)\r\n",
    "    m = AL.shape[1]\r\n",
    "    Y = Y.reshape(AL.shape)\r\n",
    "\r\n",
    "    dAL = - (np.divide(Y,AL) - np.divide(1-Y,1-AL))\r\n",
    "    #dAL =  2*np.abs(np.subtract(AL,y))\r\n",
    "\r\n",
    "    current_cache = caches[L-1]\r\n",
    "\r\n",
    "    grads[\"dA\"+str(L-1)],grads[\"dW\"+str(L-1)],grads[\"db\"+str(L-1)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\r\n",
    "\r\n",
    "    for i in reversed(range(L-1)):\r\n",
    "        current_cache = caches[i]\r\n",
    "        dA_prev_temp,dW_temp,db_temp = linear_activation_backward(grads[\"dA\" + str(i + 1)], current_cache, activation = \"relu\")\r\n",
    "        grads[\"dA\" + str(i)] = dA_prev_temp\r\n",
    "        grads[\"dW\" + str(i + 1)] = dW_temp\r\n",
    "        grads[\"db\" + str(i + 1)] = db_temp \r\n",
    "\r\n",
    "    return grads   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,grads,learning_rate):\r\n",
    "    L = len(parameters)//2\r\n",
    "    for i in range(L-1):\r\n",
    "        parameters[\"W\" + str(i+1)] = parameters[\"W\" + str(i+1)] - learning_rate * grads[\"dW\" + str(i+1)]\r\n",
    "        parameters[\"b\" + str(i+1)] = parameters[\"b\" + str(i+1)] - learning_rate * grads[\"db\" + str(i+1)]\r\n",
    "    \r\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,parameters):\r\n",
    "    n = len(parameters)//2\r\n",
    "    p = np.zeros((1,m))\r\n",
    "    probas,caches = forward_pass(X,parameters)\r\n",
    "\r\n",
    "    for i in range(0, probas.shape[1]):\r\n",
    "        if probas[0,i] > 0.5:\r\n",
    "            p[0,i] = 1\r\n",
    "        else:\r\n",
    "            p[0,i] = 0\r\n",
    "    return p\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(X,y,layers_dims,epochs =3000,learning_rate = 0.0075):\r\n",
    "        # cost))\r\n",
    "        # if i % 100 == 0:\r\n",
    "        #     costs.append(cost)\r\n",
    "    costs = []\r\n",
    "    parameters = init_params(layers_dims)\r\n",
    "    \r\n",
    "    for i in range(0,epochs):\r\n",
    "        AL,caches = forward_pass(X,parameters)\r\n",
    "        \r\n",
    "        cost = compute_cost(AL,y)\r\n",
    "        \r\n",
    "        grads = backward_pass(AL,y,caches)\r\n",
    "\r\n",
    "        parameters = update_parameters(parameters,grads,learning_rate)\r\n",
    "\r\n",
    "        # if i % 100 == 0:\r\n",
    "        #     print (f\"Cost after iteration i -> {i} and cost -> {cost}\") \r\n",
    "\r\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1],\n",
       "       [0, 1, 0, 1]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\r\n",
    "y = np.array([[0,1,1,0]])\r\n",
    "\r\n",
    "X = X.reshape(X.shape[0], -1).T\r\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-262-ed3a26498a7c>:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logprodut = np.dot(Y,np.log(AL).T) + np.dot((1-Y),np.log(1-AL).T)\n",
      "<ipython-input-265-b01590f0565b>:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dAL = - (np.divide(Y,AL) - np.divide(1-Y,1-AL))\n",
      "<ipython-input-265-b01590f0565b>:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dAL = - (np.divide(Y,AL) - np.divide(1-Y,1-AL))\n"
     ]
    }
   ],
   "source": [
    "parameters = call(X,y,[2,4,3,1],10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[1,1]])\r\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).T\r\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predict(X_test,parameters)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \"  + str(np.sum((p == y)/m)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d6330bcc2c4585811edcba372def02cebd4fa2d6683ed5ef2fc59fc015e52e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}